{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e4876f",
   "metadata": {},
   "source": [
    "# Introduction to Python for Earth Scientists\n",
    "\n",
    "These notebooks have been developed by Calum Chamberlain, Finnigan Illsley-Kemp, John Townend and El Mestel at [Victoria University of Wellington-Te Herenga Waka](https://www.wgtn.ac.nz) for use by Earth Science graduate students. \n",
    "\n",
    "The notebooks cover material that we think will be of particular benefit to those students with little or no previous experience of computer-based data analysis. We presume very little background in command-line or code-based computing, and have compiled this material with an emphasis on general tasks that a grad student might encounter on a daily basis. \n",
    "\n",
    "In 2024, this material will be delivered at the start of Trimester 1 in conjunction with [ESCI451 Active Earth](https://www.wgtn.ac.nz/courses/esci/451). Space permitting, interested students not enrolled in ESCI451 are encouraged to come along too but please contact El, Calum, Finn, or John first.\n",
    "\n",
    "| Notebook | Contents | Data |\n",
    "| --- | --- | --- |\n",
    "| [1A](ESCI451_Module_1A.ipynb) | Introduction to programming, Python, and Jupyter notebooks | - |\n",
    "| [1B](ESCI451_Module_1B.ipynb) | Basic data types and variables, getting data, and plotting with Matplotlib | Geodetic positions |\n",
    "| [2A](ESCI451_Module_2A.ipynb) | More complex plotting, introduction to Numpy | Geodetic positions; DFDP-2B temperatures |\n",
    "| [2B](ESCI451_Module_2B.ipynb) | Using Pandas to load, peruse and plot data | Earthquake catalogue  |\n",
    "| [3A](ESCI451_Module_3A.ipynb) | Working with Pandas dataframes | Geochemical data set; GNSS data |\n",
    "| [3B](ESCI451_Module_3B.ipynb) | Simple time series analysis using Pandas | Historical temperature records |\n",
    "| [4A](ESCI451_Module_4A.ipynb) | Making maps with PyGMT | Earthquake catalogue |\n",
    "| **[4B](ESCI451_Module_4B.ipynb)** | **Gridded data and vectors** | **Ashfall data and GNSS** |\n",
    "| [Scripting](ESCI451_Module_5A_Scripting.ipynb) | Moving from notebooks to scripts and the command line | - |\n",
    "\n",
    "The content may change in response to students' questions or current events. Each of the four modules has been designed to take about three hours, with a short break between each of the two parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0db698",
   "metadata": {},
   "source": [
    "# Mapping Part 2: Plotting gridded data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1042db4",
   "metadata": {},
   "source": [
    "We have already done some work with gridded data, probably without even realising it! The topography that we were plotting in the last lab is a grid of elevations that we then plotted on our maps.  Lots of spatial data in Earth Sciences are best resolved on a grid, so in this lab we are going to spend some time playing around with plotting some cool gridded data.\n",
    "\n",
    "First up let's import PyGMT and some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b0cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:07.795683Z",
     "iopub.status.busy": "2024-02-20T20:59:07.795264Z",
     "iopub.status.idle": "2024-02-20T20:59:09.293757Z",
     "shell.execute_reply": "2024-02-20T20:59:09.291891Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pygmt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddebc67",
   "metadata": {},
   "source": [
    "We are going to play around with some model output Simon Barker and colleagues worked up in their [2018 paper](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GC008152) on modeling ash dispersal from future eruptions of Taupō supervolcano.\n",
    "\n",
    "All the outputs from their models are included in an online repository, as any good, modern paper should! I have taken the liberty of including one model output in the data directory and we will start by playing with that, but you should explore the data repository and get other model outputs if you want.\n",
    "\n",
    "The output of the model is ash thickness, and is modeled dependent on a few things, including wind direction.\n",
    "\n",
    "Let's start by reading the data. The data is given in ESRI-ASCII format, which is used in GIS programmes like [ArcGIS](https://www.arcgis.com/index.html). We've provided a function in `helpers` to convert this into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1e938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:09.301407Z",
     "iopub.status.busy": "2024-02-20T20:59:09.300579Z",
     "iopub.status.idle": "2024-02-20T20:59:09.348279Z",
     "shell.execute_reply": "2024-02-20T20:59:09.346798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helpers.asc_to_df import transform_asc_to_df\n",
    "\n",
    "datafile = \"data/DepositFile_ESRI_ASCII.txt\"\n",
    "df = transform_asc_to_df(datafile)\n",
    "df.rename(columns={'variable': 'thickness'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753679a",
   "metadata": {},
   "source": [
    "Now let's draw a map and some contours of ash thickness. For the contouring we use the aptly named [`contour`](https://www.pygmt.org/latest/api/generated/pygmt.Figure.contour.html) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f5775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:09.355355Z",
     "iopub.status.busy": "2024-02-20T20:59:09.354711Z",
     "iopub.status.idle": "2024-02-20T20:59:11.961579Z",
     "shell.execute_reply": "2024-02-20T20:59:11.960980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[173, 179, -42, -36],\n",
    "          shorelines=True,\n",
    "          land='grey',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne', 'xa2f1', 'ya2f1'])\n",
    "\n",
    "fig.contour(x=df['longitude'],\n",
    "            y=df['latitude'],\n",
    "            z=df['thickness'],\n",
    "            levels=1,  # draw a contour every 1mm thickness\n",
    "            annotation=10,  # annotate every 10mm\n",
    "            pen='2p')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cf3e0",
   "metadata": {},
   "source": [
    "That must have been a strong Westerly. Poor Gisbourne...\n",
    "\n",
    "There are really too many contours drawn there and it looks very messy. Let's tell PyGMT exactly which contours to plot. To do this we need to give the `levels` paramater a comma-seperated string of the contours we want. This isn't very pythonic, but hopefully this is improved in future versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604395c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:11.963874Z",
     "iopub.status.busy": "2024-02-20T20:59:11.963511Z",
     "iopub.status.idle": "2024-02-20T20:59:13.766927Z",
     "shell.execute_reply": "2024-02-20T20:59:13.766395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[173, 179, -42, -36],\n",
    "          shorelines=True,\n",
    "          land='grey',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne', 'xa2f1', 'ya2f1'])\n",
    "\n",
    "fig.contour(x=df['longitude'],\n",
    "            y=df['latitude'],\n",
    "            z=df['thickness'],\n",
    "            levels='1,5,10,15,20,25,30',  # The non-pythonic comma separated string\n",
    "            # The annotations we want to add to the contours.\n",
    "            annotation='1,5,10,15,20,25,30',\n",
    "            pen='2p')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d99c6",
   "metadata": {},
   "source": [
    "That's pretty easy and very handy for many earth science datasets. You can do something very similar with topography using the [`grdcontour`](https://www.pygmt.org/latest/api/generated/pygmt.Figure.grdcontour.html) method.\n",
    "\n",
    "**Exercise**: Now, go and download a different model run from Simon's [repository](https://www.sciencebase.gov/catalog/item/5cdd9ed7e4b029273746367a) and plot it up. The files are organised a little strangely - select a model zip file that you want, download that and extract the contents. Then select a \"run\" of that model that you want - these have different starting conditions. Extract the contents of that archive and put the file called \"DepositFile_ESRI_ASCII.txt\" in the data directory with a different name (e.g. \"DepositFile_ESRI_ASCII_5km3_Run00001.txt\" might be a sensible name if you downloaded the 5km3 dataset and extract Run00001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393c8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:13.768987Z",
     "iopub.status.busy": "2024-02-20T20:59:13.768781Z",
     "iopub.status.idle": "2024-02-20T20:59:13.771454Z",
     "shell.execute_reply": "2024-02-20T20:59:13.770960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601216c",
   "metadata": {},
   "source": [
    "# Plotting Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331aa68",
   "metadata": {},
   "source": [
    "Another common observation we deal with in Earth Science is vectors. PyGMT can handle these really nicely.\n",
    "\n",
    "For this exercise we're going to go down to Kaikōura and will begin by plotting an arbitrary vector with the [`velo`](https://www.pygmt.org/latest/api/generated/pygmt.Figure.velo.html) method. We first have to out our data into a `dataframe` and then we plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c39f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:13.773256Z",
     "iopub.status.busy": "2024-02-20T20:59:13.773109Z",
     "iopub.status.idle": "2024-02-20T20:59:15.684347Z",
     "shell.execute_reply": "2024-02-20T20:59:15.682795Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[172.5, 174.5, -43, -41.5],\n",
    "          shorelines=True,\n",
    "          land='grey',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne', 'xa0.5f0.1', 'ya0.5f0.1'])\n",
    "\n",
    "# Make a dataframe to store our data\n",
    "df = pd.DataFrame(data={\n",
    "    \"x\": [173.5],\n",
    "    \"y\": [-42],\n",
    "    \"east_velocity\": [3],\n",
    "    \"north_velocity\": [3],\n",
    "})\n",
    "\n",
    "fig.velo(data=df,\n",
    "         pen='1p,black',  # vector line\n",
    "         fill='black',  # arrow head\n",
    "         spec='e0.5/0.5',  # this is telling it to plot a vector with a scale of 0.5 cm for each unit\n",
    "         )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a885a26",
   "metadata": {},
   "source": [
    "Ok great, but that vector doesn't mean anything. Let's do something more interesting.\n",
    "\n",
    "Let's begin by importing some GNSS data using the function from our previous notebook that is also included in the helpers module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf68e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:15.690394Z",
     "iopub.status.busy": "2024-02-20T20:59:15.689709Z",
     "iopub.status.idle": "2024-02-20T20:59:15.804181Z",
     "shell.execute_reply": "2024-02-20T20:59:15.803588Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers.get_data import get_gnss_for_station\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e505ad",
   "metadata": {},
   "source": [
    "Let's use that to download some data from a Kaikōura GNSS station (you can see the map of GNSS stations [here](https://www.geonet.org.nz/data/gnss/map)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0374e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:15.806367Z",
     "iopub.status.busy": "2024-02-20T20:59:15.806185Z",
     "iopub.status.idle": "2024-02-20T20:59:16.334423Z",
     "shell.execute_reply": "2024-02-20T20:59:16.333982Z"
    }
   },
   "outputs": [],
   "source": [
    "GNSS_data = pd.DataFrame(get_gnss_for_station(\n",
    "    'KAIK', starttime=dt.datetime(2010, 1, 1), endtime=dt.datetime(2020, 1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2f1b9",
   "metadata": {},
   "source": [
    "Nice, now let's have a look at that GNSS data either side of the [Kaikōura earthquake](https://www.geonet.org.nz/earthquake/2016p858000). Remember this earthquake happened at 11:02:56 on 2016-11-13 (UTC time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954f524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:16.336347Z",
     "iopub.status.busy": "2024-02-20T20:59:16.336196Z",
     "iopub.status.idle": "2024-02-20T20:59:16.840229Z",
     "shell.execute_reply": "2024-02-20T20:59:16.839820Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(GNSS_data[\"time\"], GNSS_data[component],\n",
    "            label=component)\n",
    "\n",
    "ax.set_xlim(\n",
    "    dt.datetime(2016, 11, 6, 11, 2, 56),\n",
    "    dt.datetime(2016, 11, 20, 11, 2, 56))\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for KAIK\")\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()  # Simple fix for overlapping dates on x-axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d63eb7",
   "metadata": {},
   "source": [
    "That's quite an offset! We could calculate a vector from that displacement\n",
    "\n",
    "Let's first cut our dataset down to the two week period we're interested in. We can do this by defining a filter and using the [`loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) method on our `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8fefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:16.842114Z",
     "iopub.status.busy": "2024-02-20T20:59:16.841875Z",
     "iopub.status.idle": "2024-02-20T20:59:16.853381Z",
     "shell.execute_reply": "2024-02-20T20:59:16.852986Z"
    },
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "date_filter = (GNSS_data['time'] >= '2016/11/06T11:02:56') & (\n",
    "    GNSS_data['time'] <= '2016/11/20T11:02:56')\n",
    "\n",
    "GNSS_data.loc[date_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f150d2",
   "metadata": {},
   "source": [
    "You can see that we've filtered our dataframe so that we now only have the data covering that two week period. Now to calculate the displacement over this time-window we simply need to calculate the difference between the north and east components at the beginning and end of this time period. Here's an example of how to do this for the North component using the handy [`first_valid_index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.first_valid_index.html?highlight=first_valid_index#pandas.DataFrame.first_valid_index) and [`last_valid_index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.last_valid_index.html?highlight=last_valid_index#pandas.DataFrame.last_valid_index) methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9da431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:16.855136Z",
     "iopub.status.busy": "2024-02-20T20:59:16.854976Z",
     "iopub.status.idle": "2024-02-20T20:59:16.892497Z",
     "shell.execute_reply": "2024-02-20T20:59:16.892031Z"
    }
   },
   "outputs": [],
   "source": [
    "date_filter = (GNSS_data['time'] >= '2016/11/06T11:02:56') & (\n",
    "    GNSS_data['time'] <= '2016/11/20T11:02:56')\n",
    "\n",
    "N_first_index = GNSS_data.loc[date_filter]['north'].first_valid_index()\n",
    "N_first_value = GNSS_data['north'][N_first_index]\n",
    "\n",
    "N_last_index = GNSS_data.loc[date_filter]['north'].last_valid_index()\n",
    "N_last_value = GNSS_data['north'][N_last_index]\n",
    "\n",
    "N_disp = N_last_value - N_first_value\n",
    "\n",
    "print(f\"The displacement if {N_disp} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea16fbf",
   "metadata": {},
   "source": [
    "Now here's an **Exercise**: Calculate both the North and East displacement for this GNSS station and plot it as a vector on the map. To give you a hand I've given you some code to download the GNSS locations from GeoNet and an example of how to get the Latitude for KAIK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72feee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:16.894210Z",
     "iopub.status.busy": "2024-02-20T20:59:16.894070Z",
     "iopub.status.idle": "2024-02-20T20:59:17.233921Z",
     "shell.execute_reply": "2024-02-20T20:59:17.231954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Downloading the GNSS locations from GeoNet's GitHub\n",
    "url = (r'https://raw.githubusercontent.com/GeoNet/delta/main/network/marks.csv')\n",
    "sites = pd.read_csv(url, delimiter=\",\")\n",
    "sites.head()\n",
    "sites = sites.reset_index()\n",
    "\n",
    "site_lat = sites.loc[sites['Mark'] == 'KAIK']['Latitude']\n",
    "\n",
    "\n",
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbc336",
   "metadata": {},
   "source": [
    "Great, now write a loop that downloads data and calculates vectors for the following nearby GNSS sites (MRBL, HANM, CMBL, WITH) and then plot them on a map.\n",
    "\n",
    "You could also plot the Kaikōura [epicentre](https://www.geonet.org.nz/earthquake/technical/2016p858000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242742d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T20:59:17.241198Z",
     "iopub.status.busy": "2024-02-20T20:59:17.240592Z",
     "iopub.status.idle": "2024-02-20T20:59:17.247863Z",
     "shell.execute_reply": "2024-02-20T20:59:17.246163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979f9bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Beyond GMT\n",
    "\n",
    "GMT makes really pretty plots but not this isn't by any means the only way to plot geospatial data. Below are a list of other projects you might want to check out:\n",
    "\n",
    "- [cartopy](https://scitools.org.uk/cartopy/docs/latest/) is the most \"pythonic\" map plotting library at the moment, and it is integrated with matplotlib in a way that PyGMT isn't. However, it can be painful with a lot of geospatial data. It is worth a look though and, if you are interested, we have some resources from previous years using caropty. \n",
    "- [bokeh](https://bokeh.org/) is pretty cool for creating interactive plots, including [maps](https://docs.bokeh.org/en/latest/docs/user_guide/topics/geo.html) - CJC uses this quite a bit for interogating data.\n",
    "- [follium](https://github.com/python-visualization/folium) looks nice for making interactive mapping plots - possibly better than bokeh because it is more focused on mapping.\n",
    "\n",
    "That is all for now - hopefully that has given you some idea of how you can make some fairly nice plots without too much effort.  A key idea with these notebooks is for you to **borrow some code** from them so that you do not have to re-write everything yourself.\n",
    "\n",
    "# Fin\n",
    "\n",
    "Great! All being well you now know a little more about programming, and Python. At the least, we hope that this course has shown you that **you can write code** - it doesn't have to be perfect, and your skills will improve with time, *but* you now have the power to make computers do a lot of your work for you! Yay!\n",
    "\n",
    "Now you can write some code and use the legitimate excuse of every programmer (although in Python you don't have to spend time compilling, you can just run your code!):\n",
    "\n",
    "<div>\n",
    "    <img alt=\"xkcd 303 Compiling\n",
    "    The #1 Programmer Excuse for Legitimately Slacking Off: 'My code's compiling.'\n",
    "    [Two programmers are sword-fighting on office chairs in a hallway. An unseen manager calls them back to work through an open office door.]\n",
    "    Manager: Hey! Get back to work!\n",
    "    Cueball: Compiling!\n",
    "    Manager: Oh. Carry on.\" src=\"https://imgs.xkcd.com/comics/compiling.png\"><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
